{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T10:53:09.020869Z",
     "start_time": "2025-03-01T10:53:08.827512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import os\n",
    "from tsfel import time_series_features_extractor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "id": "7e32d516f4671ad0",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T10:53:52.721056Z",
     "start_time": "2025-03-01T10:53:51.667418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data(base_path):\n",
    "    def load_signals(signal_type, data_type):\n",
    "        filepaths = [os.path.join(base_path, data_type, 'Inertial Signals', f'{signal_type}_{data_type}.txt')]\n",
    "        return pd.concat([pd.read_csv(fp, delim_whitespace=True, header=None) for fp in filepaths], axis=1)\n",
    "\n",
    "    X_train = np.concatenate([\n",
    "        load_signals('body_acc_x', 'train').values[:, :, None],\n",
    "        load_signals('body_acc_y', 'train').values[:, :, None],\n",
    "        load_signals('body_acc_z', 'train').values[:, :, None],\n",
    "        load_signals('body_gyro_x', 'train').values[:, :, None],\n",
    "        load_signals('body_gyro_y', 'train').values[:, :, None],\n",
    "        load_signals('body_gyro_z', 'train').values[:, :, None],\n",
    "        load_signals('total_acc_x', 'train').values[:, :, None],\n",
    "        load_signals('total_acc_y', 'train').values[:, :, None],\n",
    "        load_signals('total_acc_z', 'train').values[:, :, None]\n",
    "    ], axis=2)\n",
    "\n",
    "    X_test = np.concatenate([\n",
    "        load_signals('body_acc_x', 'test').values[:, :, None],\n",
    "        load_signals('body_acc_y', 'test').values[:, :, None],\n",
    "        load_signals('body_acc_z', 'test').values[:, :, None],\n",
    "        load_signals('body_gyro_x', 'test').values[:, :, None],\n",
    "        load_signals('body_gyro_y', 'test').values[:, :, None],\n",
    "        load_signals('body_gyro_z', 'test').values[:, :, None],\n",
    "        load_signals('total_acc_x', 'test').values[:, :, None],\n",
    "        load_signals('total_acc_y', 'test').values[:, :, None],\n",
    "        load_signals('total_acc_z', 'test').values[:, :, None]\n",
    "    ], axis=2)\n",
    "    y_train = pd.read_csv(os.path.join(base_path, 'train', 'y_train.txt'), header=None).values.ravel() - 1\n",
    "    y_test = pd.read_csv(os.path.join(base_path, 'test', 'y_test.txt'), header=None).values.ravel() - 1\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "base_path = 'UCI-HAR Dataset'\n",
    "X_train, X_test, y_train, y_test = load_data(base_path)\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ],
   "id": "ff7e422cdf39e990",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (7352, 128, 9)\n",
      "Shape of X_test: (2947, 128, 9)\n",
      "Shape of y_train: (7352,)\n",
      "Shape of y_test: (2947,)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T12:04:52.852099Z",
     "start_time": "2025-03-01T11:00:45.425733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tsfel\n",
    "from pandas import DataFrame\n",
    "\n",
    "def extract_features_tsfel(X, y, window_size=128):\n",
    "    cfg = tsfel.get_features_by_domain()\n",
    "\n",
    "    signals = {}\n",
    "    for j in range(X.shape[2]):\n",
    "        signals[f'channel_{j+1}'] = X[:, :, j].flatten()\n",
    "\n",
    "    n_samples = X.shape[0]\n",
    "    signal_df = pd.DataFrame(signals)\n",
    "\n",
    "    #  window_size=window_size\n",
    "    features = tsfel.time_series_features_extractor(cfg, signal_df, window_size=window_size)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "extracted_train_features_tsfel = extract_features_tsfel(X_train, y_train)\n",
    "extracted_test_features_tsfel = extract_features_tsfel(X_test, y_test)\n",
    "\n",
    "extracted_train_features_tsfel = extracted_train_features_tsfel.fillna(extracted_train_features_tsfel.mean())\n",
    "extracted_test_features_tsfel = extracted_test_features_tsfel.fillna(extracted_test_features_tsfel.mean())\n",
    "\n",
    "print(\"Shape of extracted_train_features_tsfel:\", extracted_train_features_tsfel.shape)\n",
    "print(\"Shape of extracted_test_features_tsfel:\", extracted_test_features_tsfel.shape)\n"
   ],
   "id": "4ed22bf1ab74eeb6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "              <p>\n",
       "                  Progress: 100% Complete\n",
       "              <p/>\n",
       "              <progress\n",
       "                  value='7352'\n",
       "                  max='7352',\n",
       "                  style='width: 25%',\n",
       "              >\n",
       "                  7352\n",
       "              </progress>\n",
       "\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "              <p>\n",
       "                  Progress: 100% Complete\n",
       "              <p/>\n",
       "              <progress\n",
       "                  value='2947'\n",
       "                  max='2947',\n",
       "                  style='width: 25%',\n",
       "              >\n",
       "                  2947\n",
       "              </progress>\n",
       "\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of extracted_train_features_tsfel: (7352, 1404)\n",
      "Shape of extracted_test_features_tsfel: (2947, 1404)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T13:17:40.891452Z",
     "start_time": "2025-03-01T13:17:40.888909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(extracted_train_features_tsfel.columns)\n",
    "print(extracted_test_features_tsfel.columns)"
   ],
   "id": "d71ff22796dc590d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['channel_1_Absolute energy', 'channel_1_Area under the curve',\n",
      "       'channel_1_Autocorrelation', 'channel_1_Average power',\n",
      "       'channel_1_Centroid', 'channel_1_ECDF Percentile Count_0',\n",
      "       'channel_1_ECDF Percentile Count_1', 'channel_1_ECDF Percentile_0',\n",
      "       'channel_1_ECDF Percentile_1', 'channel_1_ECDF_0',\n",
      "       ...\n",
      "       'channel_9_Wavelet variance_12.5Hz',\n",
      "       'channel_9_Wavelet variance_2.78Hz',\n",
      "       'channel_9_Wavelet variance_25.0Hz',\n",
      "       'channel_9_Wavelet variance_3.12Hz',\n",
      "       'channel_9_Wavelet variance_3.57Hz',\n",
      "       'channel_9_Wavelet variance_4.17Hz', 'channel_9_Wavelet variance_5.0Hz',\n",
      "       'channel_9_Wavelet variance_6.25Hz',\n",
      "       'channel_9_Wavelet variance_8.33Hz', 'channel_9_Zero crossing rate'],\n",
      "      dtype='object', length=1404)\n",
      "Index(['channel_1_Absolute energy', 'channel_1_Area under the curve',\n",
      "       'channel_1_Autocorrelation', 'channel_1_Average power',\n",
      "       'channel_1_Centroid', 'channel_1_ECDF Percentile Count_0',\n",
      "       'channel_1_ECDF Percentile Count_1', 'channel_1_ECDF Percentile_0',\n",
      "       'channel_1_ECDF Percentile_1', 'channel_1_ECDF_0',\n",
      "       ...\n",
      "       'channel_9_Wavelet variance_12.5Hz',\n",
      "       'channel_9_Wavelet variance_2.78Hz',\n",
      "       'channel_9_Wavelet variance_25.0Hz',\n",
      "       'channel_9_Wavelet variance_3.12Hz',\n",
      "       'channel_9_Wavelet variance_3.57Hz',\n",
      "       'channel_9_Wavelet variance_4.17Hz', 'channel_9_Wavelet variance_5.0Hz',\n",
      "       'channel_9_Wavelet variance_6.25Hz',\n",
      "       'channel_9_Wavelet variance_8.33Hz', 'channel_9_Zero crossing rate'],\n",
      "      dtype='object', length=1404)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T13:23:00.073177Z",
     "start_time": "2025-03-01T13:23:00.059874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "extracted_train_features_tsfel['label'] = y_train\n",
    "extracted_test_features_tsfel['label'] = y_test\n",
    "\n",
    "print(\"Shape of extracted_train_features_tsfel:\", extracted_train_features_tsfel.shape)\n",
    "print(\"Shape of extracted_test_features_tsfel:\", extracted_test_features_tsfel.shape)"
   ],
   "id": "d5a92b70a797e3b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of extracted_train_features_tsfel: (7352, 1405)\n",
      "Shape of extracted_test_features_tsfel: (2947, 1405)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T13:24:30.980620Z",
     "start_time": "2025-03-01T13:24:30.670861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def scale_data(df_train, df_test):\n",
    "    y_train = df_train['label'].values\n",
    "    y_test = df_test['label'].values\n",
    "\n",
    "    X_train = df_train.drop('label', axis=1)\n",
    "    X_test = df_test.drop('label', axis=1)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test, scaler\n",
    "\n",
    "X_train_scaled_tsfel, X_test_scaled_tsfel, y_train_tsfel, y_test_tsfel, scaler_tsfel = scale_data(extracted_train_features_tsfel, extracted_test_features_tsfel)\n",
    "\n",
    "print(\"Shape of X_train_scaled_tsfel:\", X_train_scaled_tsfel.shape)\n",
    "print(\"Shape of X_test_scaled_tsfel:\", X_test_scaled_tsfel.shape)\n",
    "print(\"Shape of y_train_tsfel:\", y_train_tsfel.shape)\n",
    "print(\"Shape of y_test_tsfel:\", y_test_tsfel.shape)"
   ],
   "id": "79d21a325ebc942a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_scaled_tsfel: (7352, 1404)\n",
      "Shape of X_test_scaled_tsfel: (2947, 1404)\n",
      "Shape of y_train_tsfel: (7352,)\n",
      "Shape of y_test_tsfel: (2947,)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T13:32:19.352291Z",
     "start_time": "2025-03-01T13:31:48.927937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tsfel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def train_evaluate_model(model, X_train, X_test, y_train, y_test, model_name=\"Model\"):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(f\"--- Classification Report for {model_name} ---\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(f\"--- Confusion Matrix for {model_name} ---\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\n\")\n",
    "\n",
    "rf_tsfel = RandomForestClassifier(random_state=42)\n",
    "svm_tsfel = SVC(random_state=42)\n",
    "lr_tsfel = LogisticRegression(random_state=42, solver='liblinear', multi_class='ovr')\n",
    "\n",
    "train_evaluate_model(rf_tsfel, X_train_scaled_tsfel, X_test_scaled_tsfel, y_train_tsfel, y_test_tsfel, model_name=\"Random Forest (TSFEL)\")\n",
    "train_evaluate_model(svm_tsfel, X_train_scaled_tsfel, X_test_scaled_tsfel, y_train_tsfel, y_test_tsfel, model_name=\"SVM (TSFEL)\")\n",
    "train_evaluate_model(lr_tsfel, X_train_scaled_tsfel, X_test_scaled_tsfel, y_train_tsfel, y_test_tsfel, model_name=\"Logistic Regression (TSFEL)\")\n"
   ],
   "id": "69bb3268829e86f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Classification Report for Random Forest (TSFEL) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97       496\n",
      "           1       0.90      0.96      0.93       471\n",
      "           2       0.96      0.83      0.89       420\n",
      "           3       0.89      0.89      0.89       491\n",
      "           4       0.90      0.90      0.90       532\n",
      "           5       1.00      1.00      1.00       537\n",
      "\n",
      "    accuracy                           0.93      2947\n",
      "   macro avg       0.93      0.93      0.93      2947\n",
      "weighted avg       0.93      0.93      0.93      2947\n",
      "\n",
      "--- Confusion Matrix for Random Forest (TSFEL) ---\n",
      "[[490   0   6   0   0   0]\n",
      " [ 10 454   7   0   0   0]\n",
      " [ 19  51 350   0   0   0]\n",
      " [  0   0   0 438  53   0]\n",
      " [  0   0   0  53 479   0]\n",
      " [  0   0   0   0   0 537]]\n",
      "\n",
      "\n",
      "--- Classification Report for SVM (TSFEL) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       496\n",
      "           1       0.98      0.96      0.97       471\n",
      "           2       0.96      0.95      0.96       420\n",
      "           3       0.94      0.89      0.91       491\n",
      "           4       0.90      0.94      0.92       532\n",
      "           5       1.00      1.00      1.00       537\n",
      "\n",
      "    accuracy                           0.95      2947\n",
      "   macro avg       0.95      0.95      0.95      2947\n",
      "weighted avg       0.95      0.95      0.95      2947\n",
      "\n",
      "--- Confusion Matrix for SVM (TSFEL) ---\n",
      "[[483   1  12   0   0   0]\n",
      " [ 15 453   3   0   0   0]\n",
      " [ 10   9 401   0   0   0]\n",
      " [  0   1   0 436  54   0]\n",
      " [  0   0   2  30 500   0]\n",
      " [  0   0   1   0   0 536]]\n",
      "\n",
      "\n",
      "--- Classification Report for Logistic Regression (TSFEL) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       496\n",
      "           1       0.98      0.97      0.98       471\n",
      "           2       1.00      0.96      0.98       420\n",
      "           3       0.93      0.86      0.89       491\n",
      "           4       0.88      0.95      0.91       532\n",
      "           5       0.99      0.99      0.99       537\n",
      "\n",
      "    accuracy                           0.96      2947\n",
      "   macro avg       0.96      0.96      0.96      2947\n",
      "weighted avg       0.96      0.96      0.96      2947\n",
      "\n",
      "--- Confusion Matrix for Logistic Regression (TSFEL) ---\n",
      "[[495   1   0   0   0   0]\n",
      " [  8 459   1   3   0   0]\n",
      " [  5   9 405   0   1   0]\n",
      " [  0   1   0 421  66   3]\n",
      " [  0   0   0  29 503   0]\n",
      " [  0   0   0   0   3 534]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# author provided features comparison",
   "id": "d089dbfe701ade7e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T13:41:25.865710Z",
     "start_time": "2025-03-01T13:40:22.374308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_raw_data(base_path):\n",
    "    def load_signals(signal_type, data_type):\n",
    "        filepaths = [os.path.join(base_path, data_type, 'Inertial Signals', f'{signal_type}_{data_type}.txt')]\n",
    "        return pd.concat([pd.read_csv(fp, delim_whitespace=True, header=None) for fp in filepaths], axis=1)\n",
    "\n",
    "    X_train = np.concatenate([\n",
    "        load_signals('body_acc_x', 'train').values,\n",
    "        load_signals('body_acc_y', 'train').values,\n",
    "        load_signals('body_acc_z', 'train').values,\n",
    "        load_signals('body_gyro_x', 'train').values,\n",
    "        load_signals('body_gyro_y', 'train').values,\n",
    "        load_signals('body_gyro_z', 'train').values,\n",
    "        load_signals('total_acc_x', 'train').values,\n",
    "        load_signals('total_acc_y', 'train').values,\n",
    "        load_signals('total_acc_z', 'train').values\n",
    "    ], axis=1)\n",
    "\n",
    "    X_test = np.concatenate([\n",
    "        load_signals('body_acc_x', 'test').values,\n",
    "        load_signals('body_acc_y', 'test').values,\n",
    "        load_signals('body_acc_z', 'test').values,\n",
    "        load_signals('body_gyro_x', 'test').values,\n",
    "        load_signals('body_gyro_y', 'test').values,\n",
    "        load_signals('body_gyro_z', 'test').values,\n",
    "        load_signals('total_acc_x', 'test').values,\n",
    "        load_signals('total_acc_y', 'test').values,\n",
    "        load_signals('total_acc_z', 'test').values\n",
    "    ], axis=1)\n",
    "    # Load labels\n",
    "    y_train = pd.read_csv(os.path.join(base_path, 'train', 'y_train.txt'), header=None).values.ravel() - 1\n",
    "    y_test = pd.read_csv(os.path.join(base_path, 'test', 'y_test.txt'), header=None).values.ravel() - 1\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train_author, X_test_author, y_train_author, y_test_author = load_raw_data(base_path)\n",
    "\n",
    "scaler_author = StandardScaler()\n",
    "X_train_scaled_author = scaler_author.fit_transform(X_train_author)\n",
    "X_test_scaled_author = scaler_author.transform(X_test_author)\n",
    "\n",
    "rf_author = RandomForestClassifier(random_state=42)\n",
    "svm_author = SVC(random_state=42)\n",
    "lr_author = LogisticRegression(random_state=42, solver='liblinear', multi_class='ovr')\n",
    "\n",
    "train_evaluate_model(rf_author, X_train_scaled_author, X_test_scaled_author, y_train_author, y_test_author, model_name=\"Random Forest (Author)\")\n",
    "train_evaluate_model(svm_author, X_train_scaled_author, X_test_scaled_author, y_train_author, y_test_author, model_name=\"SVM (Author)\")\n",
    "train_evaluate_model(lr_author, X_train_scaled_author, X_test_scaled_author, y_train_author, y_test_author, model_name=\"Logistic Regression (Author)\")"
   ],
   "id": "be7af455eac439d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Classification Report for Random Forest (Author) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83       496\n",
      "           1       0.86      0.78      0.82       471\n",
      "           2       0.85      0.87      0.86       420\n",
      "           3       0.76      0.79      0.77       491\n",
      "           4       0.81      0.77      0.79       532\n",
      "           5       1.00      1.00      1.00       537\n",
      "\n",
      "    accuracy                           0.85      2947\n",
      "   macro avg       0.85      0.85      0.85      2947\n",
      "weighted avg       0.85      0.85      0.85      2947\n",
      "\n",
      "--- Confusion Matrix for Random Forest (Author) ---\n",
      "[[434  25  37   0   0   0]\n",
      " [ 77 368  25   1   0   0]\n",
      " [ 33  22 365   0   0   0]\n",
      " [  2   8   0 386  95   0]\n",
      " [  1   3   0 121 407   0]\n",
      " [  0   0   0   0   0 537]]\n",
      "\n",
      "\n",
      "--- Classification Report for SVM (Author) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93       496\n",
      "           1       0.97      0.90      0.93       471\n",
      "           2       0.83      0.96      0.89       420\n",
      "           3       0.85      0.77      0.81       491\n",
      "           4       0.82      0.87      0.84       532\n",
      "           5       1.00      1.00      1.00       537\n",
      "\n",
      "    accuracy                           0.90      2947\n",
      "   macro avg       0.90      0.90      0.90      2947\n",
      "weighted avg       0.90      0.90      0.90      2947\n",
      "\n",
      "--- Confusion Matrix for SVM (Author) ---\n",
      "[[453   0  43   0   0   0]\n",
      " [  8 423  40   0   0   0]\n",
      " [ 13   3 404   0   0   0]\n",
      " [  1   7   1 379 103   0]\n",
      " [  3   0   0  68 461   0]\n",
      " [  0   1   0   0   0 536]]\n",
      "\n",
      "\n",
      "--- Classification Report for Logistic Regression (Author) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.22      0.28       496\n",
      "           1       0.48      0.44      0.46       471\n",
      "           2       0.37      0.24      0.29       420\n",
      "           3       0.58      0.77      0.66       491\n",
      "           4       0.46      0.65      0.54       532\n",
      "           5       0.99      1.00      1.00       537\n",
      "\n",
      "    accuracy                           0.57      2947\n",
      "   macro avg       0.54      0.55      0.54      2947\n",
      "weighted avg       0.55      0.57      0.55      2947\n",
      "\n",
      "--- Confusion Matrix for Logistic Regression (Author) ---\n",
      "[[111  69  94  75 147   0]\n",
      " [ 74 208  70  32  84   3]\n",
      " [109  56 100  59  96   0]\n",
      " [  0  24   2 379  86   0]\n",
      " [  3  72   2 109 346   0]\n",
      " [  0   0   0   0   0 537]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "751774bdf28bfe76"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
